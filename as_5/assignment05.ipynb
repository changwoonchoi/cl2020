{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oR3pclAb4Ht8"
   },
   "source": [
    "M2780.002400 Machine Listening (Fall 2020)\n",
    "\n",
    "Instructor: Kyogu Lee (kglee@snu.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbvqAdck4JHM"
   },
   "source": [
    "# Assignment 5: Linear Regression and Logistic Regression\n",
    "\n",
    "(75 points)\n",
    "\n",
    "**Due Date : This assignment is due by 12:59PM, October 13 (Tuesday)**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Assignment\n",
    "\n",
    "Each assignment is composed of two parts: a) in the theory part, you are required to solve the problem set, write down your answers on paper (also, typing your answers using PC or tablet PC is fine), and upload the scanned version (**아무개_hw5.pdf**) via **ETL**; b) for the lab assignment, you will need to write Notebook scripts (**아무개_hw5.ipynb**) and/or functions as required and submit them electronically (via **ETL**) by the end of the due date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rSnOmJBntsv"
   },
   "source": [
    "# Theory (35 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhUSsvScn2uq"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "1.   Logistic Regression (5 pts)\n",
    "\n",
    "\n",
    " Suppose you train a logistic regression classifier and your hypothesis function is $ H_\\theta(x) = g(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2)$. Where $g$ is logistic function and $\\theta_0$, $\\theta_1$ , and $\\theta_2$ are 6, 0, and -1, respectively. Draw the decision boundaries for classification and indicate where the positive prediction is.\n",
    " \n",
    " \n",
    "![](https://doc-0k-4c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dpqho7mavfhe9duhrujd8ho9jmjg35aa/1571882400000/01830637789438172170/*/1URyvismEm3oUunwZur7GSEua3BmMZjLb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbpmsglQuuU0"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "2.   Logistic function (10 pts)\n",
    "\n",
    "\n",
    " The logistic (sigmoid) function is defined as $g(z) = \\frac{1}{1+e^{-z}}$ . It is known that the logistic function is easy to differentiate because it has a simple derivative $\\frac{\\partial }{\\partial z} g(z) = g(z) (1-g(z))$ . Derive this equation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8PrJQMTwTXJ"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "3.   Gradient descent for logistic regression (20 pts)\n",
    "\n",
    "\n",
    " Using the equation above, derive the gradient descent algorithm for logistic regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q301bhDwmR1"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "4.   (optional) Cost function for logistic regression (20 pts)\n",
    "\n",
    "\n",
    " Derive the cost function $J(\\theta)$ from the perspective of the maximum (log)likelihood; i.e., by maximizing the joint probability of $m$ training samples being correctly classified. (HINT: the probability of $y = 1$ or $0$ , given $x$, parameterized by $\\theta$ can be written more compactly as $P(y|x;\\theta) = (h_\\theta (x))^y (1 - h_\\theta (x))^{1-y}$ )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Rs_XOPK4Thp"
   },
   "source": [
    "# Lab (40pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTOGA3u44W9b"
   },
   "source": [
    "For all lab assignments, submit your Notebook file (**아무개_hw5.ipynb**) via **ETL**. The Notebook file should be named with your full name and the homework number – e.g., **아무개_hw5.ipynb**. \n",
    "\n",
    "In addition to writing Python scripts and/or functions in your Notebook file, there are also questions you’ll have to answer. For such questions, you should provide answers in your Notebook file using Text sections.\n",
    "\n",
    "**Please submit the codes executed (make sure that the results of your codes are visible in the submitted assignments) so that the grader can check whether the code is working or not.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iS-Rnmhz4kka"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "1.   Linear Regression (20 pts)\n",
    "\n",
    "\n",
    "\n",
    "*   a. Download Auto_Insurance_description.txt and Auto_Insurance.csv from course homepage or ETL (lab data). Read the data descriptions provided in Auto_Insurance_description.txt. Load Auto_Insurance.csv to your notebook session and plot the data using matplotlib.pyplot.scatter.\n",
    "\n",
    "*   b. Fit a linear regression model estimating the total payment for all the claims Swedish Kronor form the number of claims made. Plot the regression line over the scatterplot of the data. Plot the change of the cost calculated by the cost function as the model fits. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMKmy6Yp78YX"
   },
   "outputs": [],
   "source": [
    "# a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFG4e0o_77OW"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "2.   Logistic Regression (20 pts)\n",
    "\n",
    " \n",
    " \n",
    "*   a. Download haberman.data and Haberman.names from course homepage or ETL (lab data). Read the data descriptions provided in Haberman.names. Load haberman.data to your notebook session and plot the data. You may need to use 3d plotting technique.\n",
    "\n",
    "\n",
    "*   b. Fit a logistic regression model estimating the survival status. Plot the regression plane over the scatterplot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLdyTVZc8B8h"
   },
   "outputs": [],
   "source": [
    "# !!!! your code here !!!!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment05.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
